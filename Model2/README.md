## Pipeline

#### Preprocessing
- Gaussian Blur: 
    - Smooth the images
    - Reduce high-frequency noise.

- JPEG Compression:
    - Aids in reducing the overall data size
    - Beneficial for storage and transmission purposes

#### Encoding the Image
- Chose the OpenAI CLIP model with the architecture ViT-L/14 for image encoding
- Transforming the input image into a 768-dimensional feature vector.
-  Encoded representations generated by CLIP capture semantic information about the content of the images


####  Dimensionality Reduction
- Configured the autoencoder to reduce the dimensionality of the feature space from 768 to 200
- Captures the most salient aspects of the input images, facilitating faster computations and potentially improving model generalization.

####  Classification
- Employed the 200-dimensional image vectors obtained through the autoencoder dimensionality reduction as input for the image classification task.
- Utilized a variety of machine learning algorithms for classification, including Nearest Neighbours, SVM decision tree.

[![App Screenshot](https://drive.google.com/uc?id=1KE6mpSnRcyEQU4WUZpx2nzgdTMDqowWr)](https://drive.google.com/file/d/1KE6mpSnRcyEQU4WUZpx2nzgdTMDqowWr/preview)


## Results
- #### Decision Tree Classifier
    - Accuracy: 0.7250
    - Precision: 0.6945
    - Recall: 0.8033
    - F1 Score: 0.7450
- #### Nearest Neighbours
    - Accuracy: 0.8283
    - Precision: 0.8031
    - Recall: 0.8700
    - F1 Score: 0.8352
- #### Support Vector Classification
    - Accuracy: 0.7150
    - Precision: 0.6748
    - Recall: 0.8300
    - F1 Score: 0.7444
